# ğŸ›¡ï¸ Adversarial ML Toolkit

This repository provides implementations of various **adversarial attacks** and their corresponding **defense mechanisms** on machine learning models. It is structured for easy experimentation and modular evaluation.

---

## ğŸ“Œ Implemented Attacks & Defenses

| Attack Type        | Description                             | Defense Mechanism                         |
|--------------------|-----------------------------------------|-------------------------------------------|
| **FGSM Attack**     | Fast Gradient Sign Method               | Adversarial Training                      |
| **FALFA Attack**    | Feature Alignment-based Label Flipping  | kNN-based Defense                         |
| **Backdoor Attack** | Universal Trigger-based Backdoor Attack | Spectral Signature & Pruning-based Defense|

---

## ğŸ§ª How to Use

### ğŸ” Run Evaluation Notebook

To evaluate all attack and defense methods in one place:

```bash
# Open the notebook in JupyterLab, VS Code, or Google Colab
evaluation.ipynb
```

This notebook includes visualizations, performance metrics, and comparisons of model accuracy before and after applying defenses against attacks.

---

### ğŸ§ª Run Individual Pipelines

Each attack-defense experiment is organized into separate Python scripts under the `testing/` directory.

#### Example usage:

```bash
cd testing/
```

#### Available Pipelines:

```bash
# Run FGSM Attack with Adversarial Training Defense
python test_fgsm_attack_defense.py

# Run FALFA Attack with kNN-based Defense
python test_knn_defense.py

# Run Backdoor Attack with Spectral Signature + Pruning Defense
python test_pruning.py | python test_ss.py
```

---

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ evaluation.ipynb                # Main evaluation notebook
â”œâ”€â”€ testing/                        # Pipelines for attacks & defenses
â”‚   â”œâ”€â”€ test_fgsm_attack_defense.py
â”‚   â”œâ”€â”€ test_knn_defense.py
â”‚   â”œâ”€â”€ test_pruning.py
â”‚   â””â”€â”€ ...
â”œâ”€â”€ models/                         # Neural network model definitions
â”œâ”€â”€ data/                           # Sample dataset (or link to external source)
â”œâ”€â”€ utils/                          # Utility functions for attacks/defenses
â””â”€â”€ README.md                       # Project overview
```

---

## ğŸ“š References

- **FGSM** â€“ Fast Gradient Sign Method: [1Konny/FGSM](https://github.com/1Konny/FGSM)
- **Backdoor Attack & Defense** â€“ BATD: [HamidRezaTajalli/BATD](https://github.com/HamidRezaTajalli/BATD)
- **Spectral Signature Defense** â€“ *Detecting Backdoor Attacks on Deep Neural Networks by Activation Clustering*, Tran et al., 2018


---

## âš ï¸ Disclaimer

This project is for **educational and research purposes only**. Any use of adversarial attacks for malicious purposes is strictly discouraged.

---
